# ML Trading System - Documentation Compl√®te

> Syst√®me de Machine Learning pour pr√©dictions boursi√®res avec XGBoost + LSTM

## üìã Table des Mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Modules](#modules)
- [Entra√Ænement](#entra√Ænement)
- [Backtesting](#backtesting)
- [API Reference](#api-reference)
- [Performance](#performance)

---

## üéØ Vue d'ensemble

Ce syst√®me ML combine **XGBoost** (classification) et **LSTM** (r√©gression) pour pr√©dire les mouvements de prix d'actions avec une pr√©cision cible de **75-80%** et un Sharpe ratio **>2.0**.

### Caract√©ristiques principales

- ‚úÖ **100% Gratuit** - Yahoo Finance, FRED API, pas de co√ªts
- ‚úÖ **50+ Features** - Indicateurs techniques, macro, sentiment, volume
- ‚úÖ **Multi-horizon** - Pr√©dictions 1j, 3j, 7j
- ‚úÖ **Ensemble learning** - Combine XGBoost + LSTM
- ‚úÖ **Backtesting r√©aliste** - Backtrader avec slippage et commissions
- ‚úÖ **Google Colab** - Entra√Ænement GPU gratuit
- ‚úÖ **Walk-forward validation** - √âvite l'overfitting
- ‚úÖ **Monte Carlo** - 10k+ simulations pour risk management
- ‚úÖ **Dashboards Plotly** - Visualisations interactives

### Objectifs de performance

| M√©trique | Objectif |
|----------|----------|
| Accuracy (classification) | >72% |
| MAPE (r√©gression) | <5% |
| Sharpe Ratio | >2.0 |
| Max Drawdown | <20% |
| Win Rate | >55% |

---

## üèóÔ∏è Architecture

```
ml_models/
‚îú‚îÄ‚îÄ data_collection/          # T√©l√©chargement donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ yahoo_finance_downloader.py
‚îÇ   ‚îú‚îÄ‚îÄ fred_macro_downloader.py
‚îÇ   ‚îî‚îÄ‚îÄ data_cache.py
‚îÇ
‚îú‚îÄ‚îÄ feature_engineering/      # Cr√©ation features
‚îÇ   ‚îú‚îÄ‚îÄ technical_indicators.py   # RSI, MACD, Bollinger, etc.
‚îÇ   ‚îú‚îÄ‚îÄ macro_features.py         # Fed funds, inflation, VIX
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_features.py     # Reddit, news, StockTwits
‚îÇ   ‚îú‚îÄ‚îÄ volume_features.py        # Volume analysis
‚îÇ   ‚îî‚îÄ‚îÄ feature_selector.py       # Top 50 selection
‚îÇ
‚îú‚îÄ‚îÄ models/                   # Mod√®les ML
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_classifier.py     # Classification UP/DOWN/FLAT
‚îÇ   ‚îú‚îÄ‚îÄ lstm_predictor.py         # LSTM price prediction
‚îÇ   ‚îú‚îÄ‚îÄ ensemble_model.py         # Combine les deux
‚îÇ   ‚îî‚îÄ‚îÄ model_trainer.py          # Script d'entra√Ænement
‚îÇ
‚îú‚îÄ‚îÄ backtesting/              # Backtesting & validation
‚îÇ   ‚îú‚îÄ‚îÄ backtest_engine.py        # Backtrader strategy
‚îÇ   ‚îú‚îÄ‚îÄ cost_models.py            # Commissions, slippage
‚îÇ   ‚îú‚îÄ‚îÄ walk_forward_validator.py # Validation rolling
‚îÇ   ‚îú‚îÄ‚îÄ performance_metrics.py    # Sharpe, Sortino, Calmar
‚îÇ   ‚îî‚îÄ‚îÄ monte_carlo_simulator.py  # Simulations MC
‚îÇ
‚îú‚îÄ‚îÄ visualization/            # Dashboards
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py          # Plotly charts
‚îÇ
‚îî‚îÄ‚îÄ saved_models/             # Mod√®les entra√Æn√©s
    ‚îî‚îÄ‚îÄ {TICKER}/
        ‚îú‚îÄ‚îÄ xgboost/
        ‚îú‚îÄ‚îÄ lstm/
        ‚îî‚îÄ‚îÄ ensemble/
```

---

## üì¶ Installation

### Pr√©requis

- Python 3.9+
- pip

### Installation locale

```bash
# 1. Cloner le repo
cd helixone-backend

# 2. Installer d√©pendances ML
pip install -r requirements_ml.txt

# 3. Configuration FRED API (gratuit)
# S'inscrire sur https://fred.stlouisfed.org/docs/api/api_key.html
# Cr√©er .env avec:
FRED_API_KEY=your_api_key_here
```

### Google Colab (GPU gratuit)

```python
# Dans un notebook Colab:

# 1. Uploader ml_models/ et requirements_ml.txt

# 2. Installer d√©pendances
!pip install -r requirements_ml.txt

# 3. Monter Google Drive (pour sauvegarder mod√®les)
from google.colab import drive
drive.mount('/content/drive')

# 4. Pr√™t √† entra√Æner!
```

---

## üöÄ Quick Start

### 1. Entra√Æner un mod√®le (5 minutes)

```bash
# Entra√Æner AAPL avec ensemble (XGBoost + LSTM)
python ml_models/model_trainer.py --ticker AAPL --mode ensemble --lstm-epochs 50

# Outputs:
# - Mod√®les: ml_models/saved_models/AAPL/
# - Dataset: ml_models/results/AAPL_dataset.csv
# - Logs: terminal
```

### 2. Backtester la strat√©gie

```python
from ml_models.backtesting.backtest_engine import BacktestEngine

engine = BacktestEngine()

results = engine.run_backtest(
    ticker='AAPL',
    model_path='ml_models/saved_models/AAPL/ensemble',
    features=['rsi_14', 'macd', 'bb_width', 'sma_20', 'volume_ratio'],
    start_date='2022-01-01',
    initial_cash=100000
)

# R√©sultats:
# - Total return: +XX%
# - Sharpe ratio: X.XX
# - Max drawdown: -XX%
# - Win rate: XX%
```

### 3. Obtenir un signal de trading

```python
from ml_models.models.ensemble_model import MultiHorizonEnsemble
from ml_models.data_collection.data_cache import DataCache

# Charger mod√®le
ensemble = MultiHorizonEnsemble()
ensemble.load_all('ml_models/saved_models/AAPL/ensemble')

# T√©l√©charger donn√©es r√©centes
cache = DataCache()
data = cache.get_ml_dataset(['AAPL'], start_date='2023-01-01')
df = data['AAPL']

# Ajouter features (simplified)
from ml_models.feature_engineering.technical_indicators import TechnicalIndicators
tech = TechnicalIndicators()
df = tech.add_all_indicators(df)

# Obtenir signal
signal = ensemble.get_multi_horizon_signals(df, features=df.columns)

print(signal)
# {
#   'signals': {
#     '1d': {'action': 'BUY', 'confidence': 0.85, ...},
#     '3d': {'action': 'BUY', 'confidence': 0.78, ...},
#     '7d': {'action': 'HOLD', 'confidence': 0.65, ...}
#   },
#   'consensus': {'action': 'BUY', 'score': 66.7, 'confidence': 0.76}
# }
```

---

## üìä Modules

### 1. Data Collection

#### Yahoo Finance Downloader

T√©l√©charge donn√©es historiques avec cache SQLite.

```python
from ml_models.data_collection.yahoo_finance_downloader import YahooFinanceDownloader

downloader = YahooFinanceDownloader()

# T√©l√©charger 1 ticker
data = downloader.download_historical_data(
    tickers=['AAPL'],
    start_date='2020-01-01'
)

# T√©l√©charger S&P 500 complet (parall√®le)
sp500_data = downloader.download_sp500(
    start_date='2020-01-01',
    max_workers=10
)
```

**Features**:
- Cache SQLite (√©vite re-t√©l√©chargement)
- T√©l√©chargement parall√®le
- Mises √† jour incr√©mentales
- S&P 500 auto-download

#### FRED Macro Downloader

T√©l√©charge 20+ indicateurs macro-√©conomiques.

```python
from ml_models.data_collection.fred_macro_downloader import FredMacroDownloader

downloader = FredMacroDownloader(api_key='your_key')

# T√©l√©charger tous indicateurs
macro_data = downloader.download_all_indicators(
    start_date='2020-01-01'
)

# Colonnes:
# - DFF (Fed Funds Rate)
# - DGS10, DGS2 (Treasury yields)
# - CPIAUCSL (Inflation)
# - UNRATE (Unemployment)
# - VIXCLS (VIX)
# + 15 autres + derived indicators
```

### 2. Feature Engineering

#### Technical Indicators

50+ indicateurs techniques avec pandas-ta.

```python
from ml_models.feature_engineering.technical_indicators import TechnicalIndicators

tech = TechnicalIndicators()
df = tech.add_all_indicators(df)

# Ajoute:
# - Trend: SMA, EMA, MACD, ADX
# - Momentum: RSI, Stochastic, ROC, Williams %R
# - Volatility: Bollinger Bands, ATR, Keltner Channel
# - Volume: OBV, CMF, MFI
# - Candlestick patterns
```

#### Feature Selector

S√©lectionne top 50 features les plus pr√©dictives.

```python
from ml_models.feature_engineering.feature_selector import FeatureSelector

selector = FeatureSelector(max_features=50)

selected_features = selector.select_features(
    X=df[all_features],
    y=labels,
    method='xgboost'  # ou 'rf', 'rfe'
)

# M√©thodes:
# 1. Variance threshold (√©liminer constantes)
# 2. Correlation (√©liminer >0.95 corr√©l√©es)
# 3. XGBoost feature importance
```

### 3. ML Models

#### XGBoost Classifier

Classification UP/DOWN/FLAT (3 classes).

```python
from ml_models.models.xgboost_classifier import MultiHorizonClassifier

clf = MultiHorizonClassifier()

# Entra√Æner 3 horizons (1j, 3j, 7j)
clf.train_all(
    df=df,
    features=selected_features,
    train_split=0.8,
    optimize=True,       # Optuna hyperparameter tuning
    n_trials=50
)

# Obtenir signal
signal = clf.get_multi_horizon_signal(df[features])
# {'1d': {'prediction': 'UP', 'confidence': 0.85, 'action': 'BUY'}, ...}
```

**Classes**:
- **UP**: Price change > +1%
- **DOWN**: Price change < -1%
- **FLAT**: Price change entre -1% et +1%

#### LSTM Predictor

R√©gression de prix avec LSTM.

```python
from ml_models.models.lstm_predictor import MultiHorizonLSTM

lstm = MultiHorizonLSTM(lookback_window=30, lstm_units=[64, 32])

# Entra√Æner
lstm.train_all(
    df=df,
    features=features,
    epochs=100,
    batch_size=32
)

# Pr√©dire
predictions = lstm.get_multi_horizon_predictions(df, features)
# {
#   '1d': {'predicted_price': 152.50, 'price_change_pct': +2.3, ...},
#   '3d': {'predicted_price': 155.00, 'price_change_pct': +4.1, ...},
#   ...
# }
```

#### Ensemble Model

Combine XGBoost + LSTM avec weighted average.

```python
from ml_models.models.ensemble_model import MultiHorizonEnsemble

ensemble = MultiHorizonEnsemble(xgb_weight=0.5, lstm_weight=0.5)

# Entra√Æner (entra√Æne XGBoost ET LSTM)
ensemble.train_all(
    df=df,
    features=features,
    xgb_trials=30,
    lstm_epochs=100
)

# Signal combin√©
signal = ensemble.get_multi_horizon_signals(df, features)
# Consensus entre XGBoost et LSTM
```

### 4. Backtesting

#### Backtest Engine

Backtrader avec strat√©gie ML.

```python
from ml_models.backtesting.backtest_engine import BacktestEngine

engine = BacktestEngine()

results = engine.run_backtest(
    ticker='AAPL',
    model_path='ml_models/saved_models/AAPL/ensemble',
    features=selected_features,
    start_date='2022-01-01',
    initial_cash=100000,
    commission=0.001,           # 0.1%
    confidence_threshold=0.6,   # Trade si confiance >60%
    stop_loss_pct=-0.10,        # Stop loss -10%
    take_profit_pct=0.20        # Take profit +20%
)

# R√©sultats:
# - Sharpe ratio
# - Max drawdown
# - Win rate
# - Total return
# - Liste des trades
```

#### Performance Metrics

M√©triques de trading professionnelles.

```python
from ml_models.backtesting.performance_metrics import PerformanceMetrics

calc = PerformanceMetrics(risk_free_rate=0.02)

metrics = calc.calculate_all(prices=equity_curve)

# M√©triques:
# - Total return, CAGR
# - Volatility, Max drawdown
# - Sharpe, Sortino, Calmar
# - VaR, CVaR
# - Win rate, Profit factor
```

#### Monte Carlo Simulator

Simulations pour quantifier l'incertitude.

```python
from ml_models.backtesting.monte_carlo_simulator import MonteCarloSimulator

sim = MonteCarloSimulator(n_simulations=10000, forecast_days=252)

results = sim.run_simulation(
    returns=historical_returns,
    initial_value=100000,
    method='historical'  # ou 'normal', 't-student'
)

# R√©sultats:
# - Percentiles (P5, P25, P50, P75, P95)
# - VaR, CVaR
# - Probabilit√©s (profit, loss >10%, gain >20%)
# - 10k trajectoires
```

### 5. Visualization

Dashboards Plotly interactifs.

```python
from ml_models.visualization.visualization import MLVisualizer

viz = MLVisualizer(template='plotly_dark')

# Dashboard complet
fig = viz.create_dashboard(
    equity=equity_curve,
    returns=returns,
    benchmark=sp500_benchmark,
    feature_importance=importances
)

# Sauvegarder HTML
viz.save_html(fig, 'results/dashboard.html')

# Ou afficher
fig.show()
```

**Charts**:
- Equity curve vs benchmark
- Drawdown
- Returns distribution + Q-Q plot
- Monthly returns heatmap
- Feature importance
- Rolling Sharpe
- Monte Carlo fan chart

---

## üéì Entra√Ænement

### Option 1: Single Ticker (local)

```bash
python ml_models/model_trainer.py \
    --ticker AAPL \
    --mode ensemble \
    --start-date 2018-01-01 \
    --xgb-trials 50 \
    --lstm-epochs 100
```

### Option 2: Multiple Tickers

```bash
python ml_models/model_trainer.py \
    --tickers "AAPL,MSFT,GOOGL,AMZN,TSLA" \
    --mode ensemble \
    --xgb-trials 20 \
    --lstm-epochs 50
```

### Option 3: Google Colab (GPU)

```python
# Notebook Colab
!python ml_models/model_trainer.py \
    --ticker AAPL \
    --mode ensemble \
    --lstm-epochs 200 \  # Plus d'√©poques avec GPU
    --output-dir /content/drive/MyDrive/models
```

### Walk-Forward Validation

```python
from ml_models.backtesting.walk_forward_validator import WalkForwardValidator

validator = WalkForwardValidator(
    train_window_days=252,  # 1 an train
    test_window_days=63,    # 3 mois test
    step_days=21            # Avancer 1 mois
)

results = validator.validate(
    df=df,
    train_fn=train_function,
    predict_fn=predict_function,
    metric_fn=accuracy_function
)

# R√©sultats:
# - Score moyen sur toutes les windows
# - √âcart-type (stabilit√©)
# - Min/max scores
```

---

## üìà Performance Attendue

### M√©triques de pr√©diction

| Horizon | Accuracy | MAPE | R¬≤ |
|---------|----------|------|-----|
| 1 jour  | 72-75%  | 2-3% | 0.65-0.75 |
| 3 jours | 70-73%  | 3-4% | 0.60-0.70 |
| 7 jours | 68-71%  | 4-5% | 0.55-0.65 |

### M√©triques de trading

| M√©trique | Valeur attendue |
|----------|-----------------|
| Sharpe Ratio | 1.8 - 2.5 |
| Max Drawdown | -15% √† -20% |
| Win Rate | 55-60% |
| Profit Factor | 1.5 - 2.0 |
| CAGR | 15-25% |

---

## üîß API Reference

### model_trainer.py

```
Arguments:
  --ticker TICKER           Single ticker √† entra√Æner
  --tickers TICKERS         Liste de tickers (comma-separated)
  --mode {xgboost,lstm,ensemble}
  --start-date DATE         Date de d√©but (YYYY-MM-DD)
  --no-optimize             D√©sactiver Optuna
  --xgb-trials N            Nombre de trials Optuna (d√©faut: 30)
  --lstm-epochs N           Nombre d'√©poques LSTM (d√©faut: 100)
  --output-dir PATH         R√©pertoire output (d√©faut: ml_models/saved_models)
  --log-level {DEBUG,INFO,WARNING}
```

---

## üí° Best Practices

### 1. √âviter l'overfitting

- ‚úÖ Utiliser walk-forward validation
- ‚úÖ Ne pas optimiser sur donn√©es de test
- ‚úÖ Feature selection (√©liminer features non pr√©dictives)
- ‚úÖ Regularization (dropout LSTM, reg_alpha/lambda XGBoost)
- ‚úÖ Early stopping

### 2. Data quality

- ‚úÖ V√©rifier NaN (dropna ou fillna intelligent)
- ‚úÖ Normaliser features pour LSTM
- ‚úÖ Aligner dates (merge macro avec prix)
- ‚úÖ Lookback minimum pour LSTM (60+ jours)

### 3. Production

- ‚úÖ Sauvegarder scaler avec LSTM
- ‚úÖ Versionner mod√®les (dates dans noms)
- ‚úÖ Re-entra√Æner r√©guli√®rement (monthly)
- ‚úÖ Monitor drift (accuracy baisse = re-train)
- ‚úÖ Logging complet

---

## üéØ Prochaines √©tapes

### Phase 2: Alternative Data (Semaine 4-6)

- [ ] Web scraping l√©gal (Yahoo Finance news)
- [ ] Reddit sentiment (PRAW API)
- [ ] GitHub activity (commits, stars)
- [ ] Job postings scraping

### Phase 3: Market Microstructure (Semaine 7-9)

- [ ] Order flow imbalance
- [ ] Bid-ask spread
- [ ] Trade size distribution
- [ ] Time & Sales analysis

### Phase 4: Network Analysis (Semaine 10-12)

- [ ] Corr√©lations sectorielles
- [ ] Supply chain networks
- [ ] Insider trading networks

### Phase 5: Deploy (Semaine 13-15)

- [ ] API REST FastAPI
- [ ] Scheduler automatique
- [ ] Alertes email/SMS
- [ ] Dashboard temps r√©el

---

## üìö Ressources

### Documentation

- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [TensorFlow/Keras LSTM](https://www.tensorflow.org/guide/keras/rnn)
- [Backtrader](https://www.backtrader.com/)
- [Plotly](https://plotly.com/python/)
- [pandas-ta](https://github.com/twopirllc/pandas-ta)

### Papers

- "XGBoost: A Scalable Tree Boosting System" (Chen & Guestrin, 2016)
- "LSTM Networks for Stock Market Prediction" (Various)
- "The Sharpe Ratio" (Sharpe, 1994)

---

## ‚ö†Ô∏è Disclaimer

Ce syst√®me est √† but √©ducatif. Le trading comporte des risques. Past performance ne garantit pas future results. Toujours tester en paper trading avant le live.

---

## üìû Support

Questions? Check:
1. README (ce fichier)
2. Docstrings dans le code
3. Exemples `if __name__ == '__main__'`
4. GitHub issues

---

**Version**: 1.0
**Derni√®re mise √† jour**: 2024-01-XX
**License**: MIT
