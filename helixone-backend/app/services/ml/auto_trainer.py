"""
Auto Trainer - Service d'entraÃ®nement automatique des modÃ¨les ML

FonctionnalitÃ©s :
- EntraÃ®nement automatique Ã  la demande
- VÃ©rification de l'Ã¢ge des modÃ¨les
- Re-entraÃ®nement si modÃ¨le trop vieux
- Logs dÃ©taillÃ©s et gestion d'erreurs
"""

import logging
import asyncio
import subprocess
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Dict, List
import os

logger = logging.getLogger(__name__)


class AutoTrainer:
    """
    Service d'entraÃ®nement automatique des modÃ¨les ML

    Usage:
        trainer = AutoTrainer()
        success = await trainer.train_if_needed('AAPL', max_age_days=7)
    """

    def __init__(
        self,
        models_dir: Optional[str] = None,
        trainer_script: Optional[str] = None
    ):
        """
        Args:
            models_dir: RÃ©pertoire des modÃ¨les (dÃ©faut: ml_models/saved_models)
            trainer_script: Script d'entraÃ®nement (dÃ©faut: ml_models/model_trainer.py)
        """
        # Chemins
        if models_dir is None:
            base_dir = Path(__file__).parent.parent.parent.parent
            models_dir = base_dir / 'ml_models' / 'saved_models'

        if trainer_script is None:
            base_dir = Path(__file__).parent.parent.parent.parent
            trainer_script = base_dir / 'ml_models' / 'model_trainer.py'

        self.models_dir = Path(models_dir)
        self.trainer_script = Path(trainer_script)

        # VÃ©rifier que le script existe
        if not self.trainer_script.exists():
            logger.error(f"Script d'entraÃ®nement non trouvÃ© : {self.trainer_script}")

        # Lock pour Ã©viter entraÃ®nements simultanÃ©s du mÃªme ticker
        self._training_locks: Dict[str, asyncio.Lock] = {}

        logger.info(f"AutoTrainer initialisÃ©")
        logger.info(f"   ModÃ¨les: {self.models_dir}")
        logger.info(f"   Trainer: {self.trainer_script}")

    async def train_if_needed(
        self,
        ticker: str,
        max_age_days: int = 7,
        mode: str = 'xgboost',
        force: bool = False
    ) -> bool:
        """
        EntraÃ®ne un modÃ¨le si nÃ©cessaire (n'existe pas ou trop vieux)

        Args:
            ticker: Ticker de l'action
            max_age_days: Ã‚ge maximum du modÃ¨le en jours avant re-entraÃ®nement
            mode: Mode d'entraÃ®nement (xgboost ou ensemble)
            force: Force le re-entraÃ®nement mÃªme si modÃ¨le rÃ©cent

        Returns:
            bool: True si modÃ¨le prÃªt (existant valide ou nouvellement entraÃ®nÃ©)
        """
        # Lock par ticker pour Ã©viter entraÃ®nements concurrents
        if ticker not in self._training_locks:
            self._training_locks[ticker] = asyncio.Lock()

        async with self._training_locks[ticker]:
            # VÃ©rifier si modÃ¨le existe
            model_exists = self._model_exists(ticker)

            if force:
                logger.info(f"ğŸ”„ Re-entraÃ®nement forcÃ© demandÃ© pour {ticker}")
                return await self._run_training(ticker, mode)

            if not model_exists:
                logger.info(f"ğŸ”§ Aucun modÃ¨le trouvÃ© pour {ticker}, entraÃ®nement automatique...")
                return await self._run_training(ticker, mode)

            # ModÃ¨le existe, vÃ©rifier l'Ã¢ge
            age_days = self.get_model_age(ticker)

            if age_days is None:
                logger.warning(f"âš ï¸ Impossible de dÃ©terminer l'Ã¢ge du modÃ¨le {ticker}, re-entraÃ®nement...")
                return await self._run_training(ticker, mode)

            if age_days > max_age_days:
                logger.info(f"ğŸ”„ ModÃ¨le {ticker} obsolÃ¨te ({age_days}j > {max_age_days}j), re-entraÃ®nement...")
                return await self._run_training(ticker, mode)

            # ModÃ¨le valide
            logger.info(f"âœ… ModÃ¨le {ticker} existant valide (Ã¢ge: {age_days}j)")
            return True

    async def force_train(self, ticker: str, mode: str = 'xgboost') -> bool:
        """
        Force l'entraÃ®nement d'un modÃ¨le (mÃªme s'il existe et est rÃ©cent)

        Args:
            ticker: Ticker de l'action
            mode: Mode d'entraÃ®nement

        Returns:
            bool: True si succÃ¨s
        """
        return await self.train_if_needed(ticker, force=True, mode=mode)

    def _model_exists(self, ticker: str) -> bool:
        """VÃ©rifie si un modÃ¨le existe pour un ticker"""
        ticker_dir = self.models_dir / ticker

        if not ticker_dir.exists():
            return False

        # VÃ©rifier si au moins un type de modÃ¨le existe
        xgboost_dir = ticker_dir / 'xgboost'
        ensemble_dir = ticker_dir / 'ensemble'

        xgboost_exists = (xgboost_dir / 'xgb_1d.json').exists()
        ensemble_exists = (ensemble_dir / 'ensemble.pkl').exists() if ensemble_dir.exists() else False

        return xgboost_exists or ensemble_exists

    def get_model_age(self, ticker: str) -> Optional[int]:
        """
        Retourne l'Ã¢ge du modÃ¨le en jours

        Args:
            ticker: Ticker de l'action

        Returns:
            int: Ã‚ge en jours, ou None si impossible Ã  dÃ©terminer
        """
        ticker_dir = self.models_dir / ticker

        if not ticker_dir.exists():
            return None

        # Chercher le fichier training_metadata.json
        metadata_file = ticker_dir / 'training_metadata.json'

        if not metadata_file.exists():
            # Fallback : utiliser la date de modification du dossier
            mod_time = datetime.fromtimestamp(ticker_dir.stat().st_mtime)
            age = datetime.now() - mod_time
            return age.days

        try:
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)

            # Parser la date d'entraÃ®nement
            trained_at_str = metadata.get('trained_at')
            if trained_at_str:
                trained_at = datetime.fromisoformat(trained_at_str)
                age = datetime.now() - trained_at
                return age.days

            return None

        except Exception as e:
            logger.error(f"Erreur lecture mÃ©tadonnÃ©es {ticker}: {e}")
            return None

    async def _run_training(self, ticker: str, mode: str = 'xgboost') -> bool:
        """
        ExÃ©cute l'entraÃ®nement d'un modÃ¨le

        Args:
            ticker: Ticker de l'action
            mode: Mode d'entraÃ®nement (xgboost ou ensemble)

        Returns:
            bool: True si succÃ¨s
        """
        try:
            # Configuration
            start_date = os.getenv('ML_TRAIN_START_DATE', '2022-01-01')

            # Trouver l'interprÃ©teur Python du venv
            # __file__ = .../helixone-backend/app/services/ml/auto_trainer.py
            # On remonte jusqu'Ã  helixone/ (parent de helixone-backend/)
            base_dir = Path(__file__).parent.parent.parent.parent.parent
            python_exe = base_dir / 'venv' / 'bin' / 'python3'

            if not python_exe.exists():
                # Fallback sur python systÃ¨me
                python_exe = 'python3'
                logger.warning(f"Venv non trouvÃ© Ã  {base_dir / 'venv'}, utilisation de python3 systÃ¨me")

            # Le rÃ©pertoire de travail doit Ãªtre helixone-backend pour que
            # model_trainer.py utilise les bons chemins relatifs
            backend_dir = Path(__file__).parent.parent.parent.parent

            # Commande d'entraÃ®nement
            cmd = [
                str(python_exe),
                str(self.trainer_script),
                '--ticker', ticker,
                '--mode', mode,
                '--no-optimize',  # Pas d'optimisation pour Ãªtre rapide
                '--start-date', start_date
            ]

            logger.info(f"ğŸš€ Lancement entraÃ®nement {ticker} ({mode})")
            logger.info(f"   Commande: {' '.join(cmd)}")
            logger.info(f"   Working dir: {backend_dir}")

            # ExÃ©cuter avec cwd=helixone-backend pour que les chemins relatifs
            # dans model_trainer.py soient corrects
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(backend_dir)
            )

            # Attendre la fin
            stdout, stderr = await process.communicate()

            # Logger stdout/stderr pour debug
            if stdout:
                stdout_msg = stdout.decode('utf-8')
                logger.debug(f"STDOUT: {stdout_msg[-1000:]}")  # Derniers 1000 caractÃ¨res

            # VÃ©rifier le code de retour
            if process.returncode == 0:
                logger.info(f"âœ… EntraÃ®nement {ticker} terminÃ© avec succÃ¨s")

                # VÃ©rifier que le modÃ¨le a bien Ã©tÃ© crÃ©Ã©
                if not self._model_exists(ticker):
                    logger.error(f"âŒ EntraÃ®nement {ticker} a rÃ©ussi mais modÃ¨le non crÃ©Ã©!")
                    if stderr:
                        error_msg = stderr.decode('utf-8')
                        logger.error(f"   STDERR: {error_msg}")
                    return False

                # Afficher les mÃ©triques si disponibles
                self._log_training_metrics(ticker)

                return True
            else:
                logger.error(f"âŒ EntraÃ®nement {ticker} Ã©chouÃ© (code: {process.returncode})")

                # Logger stderr pour debug
                if stderr:
                    error_msg = stderr.decode('utf-8')
                    logger.error(f"   Erreur: {error_msg[:500]}")  # Premiers 500 caractÃ¨res

                return False

        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'entraÃ®nement {ticker}: {e}", exc_info=True)
            return False

    def _log_training_metrics(self, ticker: str):
        """Affiche les mÃ©triques d'entraÃ®nement dans les logs"""
        try:
            ticker_dir = self.models_dir / ticker

            # Lire mÃ©tadonnÃ©es globales
            metadata_file = ticker_dir / 'training_metadata.json'
            if metadata_file.exists():
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)

                logger.info(f"   ğŸ“Š MÃ©tadonnÃ©es {ticker}:")
                logger.info(f"      - Ã‰chantillons: {metadata.get('n_samples')}")
                logger.info(f"      - Features: {metadata.get('n_features')}")
                logger.info(f"      - DurÃ©e: {metadata.get('training_time_seconds', 0):.1f}s")

            # Lire mÃ©triques XGBoost si disponibles
            xgboost_dir = ticker_dir / 'xgboost'
            if xgboost_dir.exists():
                for horizon in ['1d', '3d', '7d']:
                    meta_file = xgboost_dir / f'xgb_{horizon}.meta.json'
                    if meta_file.exists():
                        with open(meta_file, 'r') as f:
                            meta = json.load(f)

                        metrics = meta.get('training_metrics', {})
                        val_acc = metrics.get('val_accuracy', 0)

                        logger.info(f"      - {horizon}: prÃ©cision validation = {val_acc*100:.1f}%")

        except Exception as e:
            logger.debug(f"Impossible de lire mÃ©triques {ticker}: {e}")

    def list_all_models(self) -> List[Dict]:
        """
        Liste tous les modÃ¨les disponibles avec leurs mÃ©tadonnÃ©es

        Returns:
            Liste de dictionnaires avec info sur chaque modÃ¨le
        """
        models = []

        if not self.models_dir.exists():
            return models

        for ticker_dir in self.models_dir.iterdir():
            if not ticker_dir.is_dir():
                continue

            ticker = ticker_dir.name

            # VÃ©rifier si modÃ¨le valide
            if not self._model_exists(ticker):
                continue

            # Lire mÃ©tadonnÃ©es
            metadata_file = ticker_dir / 'training_metadata.json'
            metadata = {}

            if metadata_file.exists():
                try:
                    with open(metadata_file, 'r') as f:
                        metadata = json.load(f)
                except:
                    pass

            age_days = self.get_model_age(ticker)

            models.append({
                'ticker': ticker,
                'age_days': age_days,
                'mode': metadata.get('mode', 'unknown'),
                'n_samples': metadata.get('n_samples'),
                'n_features': metadata.get('n_features'),
                'trained_at': metadata.get('trained_at'),
                'training_time': metadata.get('training_time_seconds')
            })

        return models

    async def batch_train(
        self,
        tickers: List[str],
        max_age_days: int = 7,
        mode: str = 'xgboost',
        max_concurrent: int = 2
    ) -> Dict[str, bool]:
        """
        EntraÃ®ne plusieurs tickers en parallÃ¨le (limitÃ©)

        Args:
            tickers: Liste de tickers
            max_age_days: Ã‚ge maximum
            mode: Mode d'entraÃ®nement
            max_concurrent: Nombre max d'entraÃ®nements simultanÃ©s

        Returns:
            Dict {ticker: success}
        """
        results = {}

        # CrÃ©er semaphore pour limiter concurrence
        semaphore = asyncio.Semaphore(max_concurrent)

        async def train_with_semaphore(ticker: str):
            async with semaphore:
                success = await self.train_if_needed(ticker, max_age_days, mode)
                results[ticker] = success

        # Lancer tous les entraÃ®nements
        tasks = [train_with_semaphore(ticker) for ticker in tickers]
        await asyncio.gather(*tasks)

        return results


# ============================================================================
# SINGLETON
# ============================================================================

_auto_trainer_instance: Optional[AutoTrainer] = None

def get_auto_trainer() -> AutoTrainer:
    """Retourne l'instance singleton de AutoTrainer"""
    global _auto_trainer_instance
    if _auto_trainer_instance is None:
        _auto_trainer_instance = AutoTrainer()
    return _auto_trainer_instance
