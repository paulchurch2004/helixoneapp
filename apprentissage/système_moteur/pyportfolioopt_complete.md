# üìä PyPortfolioOpt - Guide Complet pour HelixOne
## Optimisation de Portefeuille en Python

---

# TABLE DES MATI√àRES

1. [Introduction et Installation](#1-introduction-et-installation)
2. [Rendements Esp√©r√©s (Expected Returns)](#2-rendements-esp√©r√©s-expected-returns)
3. [Mod√®les de Risque (Risk Models)](#3-mod√®les-de-risque-risk-models)
4. [Fronti√®re Efficiente (Efficient Frontier)](#4-fronti√®re-efficiente-efficient-frontier)
5. [Fonctions Objectif (Objective Functions)](#5-fonctions-objectif-objective-functions)
6. [Mod√®le Black-Litterman](#6-mod√®le-black-litterman)
7. [HRP - Hierarchical Risk Parity](#7-hrp-hierarchical-risk-parity)
8. [CVaR et Semivariance](#8-cvar-et-semivariance)
9. [Allocation Discr√®te](#9-allocation-discr√®te)
10. [Exemples Complets](#10-exemples-complets)

---

# 1. INTRODUCTION ET INSTALLATION

## 1.1 Qu'est-ce que PyPortfolioOpt ?

```python
"""
PyPortfolioOpt
==============
Biblioth√®que Python pour l'optimisation de portefeuille.

Fonctionnalit√©s principales:
- MVO (Mean-Variance Optimization) - Optimisation Moyenne-Variance (Markowitz)
- Black-Litterman allocation
- HRP (Hierarchical Risk Parity) - Parit√© de Risque Hi√©rarchique
- CVaR (Conditional Value at Risk) - Valeur √† Risque Conditionnelle
- CLA (Critical Line Algorithm) - Algorithme de la Ligne Critique

Workflow typique:
1. Charger les prix historiques
2. Calculer les rendements esp√©r√©s (mu)
3. Calculer la matrice de covariance (S ou Sigma)
4. Optimiser le portefeuille
5. Obtenir l'allocation discr√®te (nombre d'actions √† acheter)
"""
```

## 1.2 Installation

```bash
# Installation standard
pip install pyportfolioopt

# Installation avec toutes les d√©pendances
pip install pyportfolioopt[all]

# D√©pendances principales
pip install pandas numpy scipy cvxpy scikit-learn
```

## 1.3 Imports de Base

```python
import pandas as pd
import numpy as np

# Imports PyPortfolioOpt
from pypfopt import EfficientFrontier
from pypfopt import risk_models
from pypfopt import expected_returns
from pypfopt import plotting
from pypfopt import objective_functions
from pypfopt import BlackLittermanModel, black_litterman
from pypfopt import HRPOpt
from pypfopt import CLA
from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices
from pypfopt.efficient_frontier import EfficientCVaR, EfficientSemivariance
```

## 1.4 Chargement des Donn√©es

```python
"""
Format des donn√©es requis:
- DataFrame pandas
- Index = dates (DatetimeIndex)
- Colonnes = tickers (symboles boursiers)
- Valeurs = prix ajust√©s (adjusted close)
"""

# M√©thode 1: Depuis un fichier CSV
df = pd.read_csv(
    "stock_prices.csv", 
    parse_dates=True, 
    index_col="date"
)

# M√©thode 2: Avec yfinance
import yfinance as yf

tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'JPM', 'BAC', 'XOM']
df = yf.download(tickers, start='2018-01-01', end='2023-12-31')['Adj Close']

print(f"Forme des donn√©es: {df.shape}")
print(f"P√©riode: {df.index[0]} √† {df.index[-1]}")
print(f"Tickers: {list(df.columns)}")
```

---

# 2. RENDEMENTS ESP√âR√âS (EXPECTED RETURNS)

## 2.1 Vue d'ensemble

```python
"""
Module expected_returns
=======================
Calcule les estimations de rendements futurs √† partir des prix historiques.

M√©thodes disponibles:
1. mean_historical_return() - Moyenne historique simple
2. ema_historical_return() - Moyenne pond√©r√©e exponentiellement (EMA)
3. capm_return() - Mod√®le CAPM (Capital Asset Pricing Model)

Par convention, les rendements sont ANNUALIS√âS (frequency=252 jours de trading).
"""
from pypfopt import expected_returns
```

## 2.2 Rendement Historique Moyen

```python
def mean_historical_return(
    prices,                    # DataFrame de prix
    returns_data=False,        # True si on passe des rendements au lieu de prix
    compounding=True,          # Moyenne g√©om√©trique (CAGR) si True, arithm√©tique sinon
    frequency=252,             # Jours de trading par an
    log_returns=False          # Utiliser les log-returns
):
    """
    Calcule le rendement historique moyen annualis√©.
    
    Formule (compounding=True):
        mu = (1 + r)^frequency - 1
        o√π r = moyenne des rendements quotidiens
    
    Formule (compounding=False):
        mu = r * frequency
    """
    pass

# Exemple d'utilisation
mu = expected_returns.mean_historical_return(df)
print("Rendements esp√©r√©s annualis√©s:")
print(mu.sort_values(ascending=False))

"""
Exemple de sortie:
AMZN    0.312
META    0.287
AAPL    0.245
MSFT    0.221
...
"""
```

## 2.3 Rendement EMA (Exponentially-Weighted Mean)

```python
def ema_historical_return(
    prices,
    returns_data=False,
    compounding=True,
    span=500,           # Fen√™tre EMA (demi-vie environ span/3)
    frequency=252,
    log_returns=False
):
    """
    Calcule le rendement moyen pond√©r√© exponentiellement.
    
    Avantage: Donne plus de poids aux donn√©es r√©centes.
    
    span=500 signifie que les donn√©es d'il y a 500 jours ont
    environ 37% du poids des donn√©es les plus r√©centes.
    """
    pass

# Exemple
mu_ema = expected_returns.ema_historical_return(df, span=180)
print("Rendements EMA (span=180):")
print(mu_ema.sort_values(ascending=False))
```

## 2.4 Rendement CAPM

```python
def capm_return(
    prices,
    market_prices=None,        # Prix du benchmark (ex: SPY)
    returns_data=False,
    risk_free_rate=0.0,        # Taux sans risque
    compounding=True,
    frequency=252,
    log_returns=False
):
    """
    Calcule les rendements esp√©r√©s selon le CAPM.
    
    Formule CAPM:
        R_i = R_f + Œ≤_i * (E(R_m) - R_f)
    
    O√π:
        R_i = rendement esp√©r√© de l'actif i
        R_f = taux sans risque (risk-free rate)
        Œ≤_i = beta de l'actif (sensibilit√© au march√©)
        E(R_m) = rendement esp√©r√© du march√©
    
    Si market_prices=None, utilise la moyenne √©quipond√©r√©e comme proxy du march√©.
    """
    pass

# Exemple avec SPY comme benchmark
spy = yf.download('SPY', start='2018-01-01', end='2023-12-31')['Adj Close']
mu_capm = expected_returns.capm_return(
    df, 
    market_prices=spy,
    risk_free_rate=0.02  # Taux sans risque de 2%
)
print("Rendements CAPM:")
print(mu_capm)
```

## 2.5 Fonctions Utilitaires

```python
# Convertir prix en rendements
returns = expected_returns.returns_from_prices(df, log_returns=False)
print(f"Rendements quotidiens: {returns.shape}")

# Convertir rendements en pseudo-prix (utile pour certaines fonctions)
pseudo_prices = expected_returns.prices_from_returns(returns)

# Fonction g√©n√©rique pour choisir la m√©thode
mu = expected_returns.return_model(
    df, 
    method="ema_historical_return",  # ou "mean_historical_return", "capm_return"
    span=200
)
```

---

# 3. MOD√àLES DE RISQUE (RISK MODELS)

## 3.1 Vue d'ensemble

```python
"""
Module risk_models
==================
Calcule la matrice de covariance des rendements.

La matrice de covariance (Œ£ ou S) est CRUCIALE car:
- Elle capture la volatilit√© de chaque actif
- Elle capture les corr√©lations entre actifs
- Elle est utilis√©e dans TOUTES les optimisations MVO

Probl√®me: La covariance √©chantillon a une HAUTE erreur d'estimation.
Solution: Techniques de shrinkage (r√©tr√©cissement) pour r√©duire l'erreur.

M√©thodes disponibles:
1. sample_cov() - Covariance √©chantillon simple
2. semicovariance() - Ne consid√®re que les rendements n√©gatifs
3. exp_cov() - Covariance pond√©r√©e exponentiellement
4. CovarianceShrinkage - M√©thodes de shrinkage (Ledoit-Wolf, OAS)
"""
from pypfopt import risk_models
```

## 3.2 Covariance √âchantillon

```python
def sample_cov(
    prices,
    returns_data=False,
    frequency=252,           # Annualisation
    log_returns=False
):
    """
    Calcule la matrice de covariance √©chantillon annualis√©e.
    
    Formule:
        S = Cov(returns) * frequency
    
    Avantages:
        - Simple et intuitif
        - Estimateur non biais√©
    
    Inconv√©nients:
        - Haute erreur d'estimation pour beaucoup d'actifs
        - L'optimiseur peut sur-pond√©rer les erreurs
    """
    pass

# Exemple
S = risk_models.sample_cov(df)
print(f"Forme de la matrice de covariance: {S.shape}")
print("\nCovariance √©chantillon:")
print(S.round(4))
```

## 3.3 Semicovariance

```python
def semicovariance(
    prices,
    returns_data=False,
    benchmark=0.000079,      # Benchmark quotidien ‚âà 2% annuel
    frequency=252,
    log_returns=False
):
    """
    Calcule la semicovariance (downside covariance).
    
    Ne consid√®re que les rendements INF√âRIEURS au benchmark.
    
    Formule:
        semicov = E[min(r_i - B, 0) * min(r_j - B, 0)]
    
    Avantage: Capture uniquement le risque de perte (downside risk).
    """
    pass

# Exemple
S_semi = risk_models.semicovariance(df, benchmark=0)  # benchmark = 0
print("Semicovariance (downside only):")
print(S_semi.round(4))
```

## 3.4 Covariance Exponentielle

```python
def exp_cov(
    prices,
    returns_data=False,
    span=180,                # Fen√™tre EMA
    frequency=252,
    log_returns=False
):
    """
    Calcule la covariance pond√©r√©e exponentiellement.
    
    Donne plus de poids aux donn√©es r√©centes.
    Utile si vous pensez que les corr√©lations r√©centes sont plus pertinentes.
    """
    pass

# Exemple
S_exp = risk_models.exp_cov(df, span=60)  # EMA sur 60 jours
print("Covariance exponentielle (span=60):")
print(S_exp.round(4))
```

## 3.5 Shrinkage de Covariance (Ledoit-Wolf)

```python
"""
Shrinkage = "R√©tr√©cissement"
============================
Combine la covariance √©chantillon avec un estimateur structur√©
pour r√©duire l'erreur d'estimation.

Formule:
    S_shrunk = Œ¥ * F + (1 - Œ¥) * S
    
O√π:
    S = covariance √©chantillon
    F = target structur√© (identit√©, facteur unique, corr√©lation constante)
    Œ¥ = param√®tre de shrinkage (0 √† 1)
"""

class CovarianceShrinkage:
    """
    Impl√©mente plusieurs m√©thodes de shrinkage.
    """
    
    def __init__(self, prices, returns_data=False, frequency=252, log_returns=False):
        pass
    
    def shrunk_covariance(self, delta=0.2):
        """Shrinkage manuel avec delta fixe."""
        pass
    
    def ledoit_wolf(self, shrinkage_target="constant_variance"):
        """
        Ledoit-Wolf shrinkage avec estimation optimale de delta.
        
        Targets disponibles:
        - "constant_variance": Identit√© √ó variance moyenne
        - "single_factor": Mod√®le √† un facteur (Sharpe)
        - "constant_correlation": Corr√©lation constante
        """
        pass
    
    def oracle_approximating(self):
        """
        OAS (Oracle Approximating Shrinkage).
        Alternative √† Ledoit-Wolf, parfois plus performante.
        """
        pass

# Exemples
cs = risk_models.CovarianceShrinkage(df)

# Ledoit-Wolf avec target "constant_variance"
S_lw = cs.ledoit_wolf(shrinkage_target="constant_variance")
print(f"Delta Ledoit-Wolf: {cs.delta:.4f}")

# Ledoit-Wolf avec target "single_factor"
S_lw_sf = risk_models.CovarianceShrinkage(df).ledoit_wolf(
    shrinkage_target="single_factor"
)

# Ledoit-Wolf avec target "constant_correlation"
S_lw_cc = risk_models.CovarianceShrinkage(df).ledoit_wolf(
    shrinkage_target="constant_correlation"
)

# Oracle Approximating Shrinkage
S_oas = risk_models.CovarianceShrinkage(df).oracle_approximating()
```

## 3.6 Fonction G√©n√©rique

```python
# Utiliser la fonction g√©n√©rique risk_matrix()
S = risk_models.risk_matrix(
    df,
    method="ledoit_wolf"  # ou "sample_cov", "semicovariance", "exp_cov", etc.
)

# M√©thodes disponibles:
methods = [
    "sample_cov",
    "semicovariance",
    "exp_cov",
    "ledoit_wolf",
    "ledoit_wolf_constant_variance",
    "ledoit_wolf_single_factor",
    "ledoit_wolf_constant_correlation",
    "oracle_approximating"
]
```

## 3.7 Utilitaires

```python
# Convertir covariance en corr√©lation
corr = risk_models.cov_to_corr(S)
print("Matrice de corr√©lation:")
print(corr.round(2))

# Convertir corr√©lation en covariance (besoin des volatilit√©s)
stdevs = np.sqrt(np.diag(S))
S_rebuilt = risk_models.corr_to_cov(corr, stdevs)

# V√©rifier/fixer les matrices non positive-semidefinite
S_fixed = risk_models.fix_nonpositive_semidefinite(S, fix_method="spectral")
# fix_method: "spectral" (met les eigenvalues n√©gatives √† 0) ou "diag"
```

---

# 4. FRONTI√àRE EFFICIENTE (EFFICIENT FRONTIER)

## 4.1 Introduction √† la MVO

```python
"""
Mean-Variance Optimization (MVO)
================================
D√©velopp√©e par Harry Markowitz (1952), Prix Nobel 1990.

Principe: Trouver le portefeuille qui:
- Maximise le rendement pour un niveau de risque donn√©, OU
- Minimise le risque pour un rendement cible

La "Fronti√®re Efficiente" est l'ensemble de tous les portefeuilles optimaux.

Formulation math√©matique (minimisation de variance):
    min   w'Œ£w
    s.t.  w'Œº ‚â• target_return
          Œ£w = 1
          w ‚â• 0 (long only)

O√π:
    w = vecteur de poids
    Œ£ = matrice de covariance
    Œº = vecteur de rendements esp√©r√©s
"""
```

## 4.2 Classe EfficientFrontier

```python
from pypfopt import EfficientFrontier

class EfficientFrontier:
    """
    Classe principale pour l'optimisation MVO.
    
    M√©thodes d'optimisation:
    - min_volatility(): Minimise la volatilit√©
    - max_sharpe(): Maximise le Sharpe Ratio (portefeuille tangent)
    - max_quadratic_utility(): Maximise l'utilit√© quadratique
    - efficient_risk(): Maximise le rendement pour une volatilit√© cible
    - efficient_return(): Minimise la volatilit√© pour un rendement cible
    """
    
    def __init__(
        self,
        expected_returns,        # pd.Series ou array de mu
        cov_matrix,              # pd.DataFrame ou array de Œ£
        weight_bounds=(0, 1),    # (min, max) pour chaque poids
        solver=None,             # Solveur CVXPY (auto par d√©faut)
        verbose=False,
        solver_options=None
    ):
        """
        Initialise l'optimiseur.
        
        weight_bounds:
            (0, 1) = long only, max 100% par actif
            (-1, 1) = permet les ventes √† d√©couvert
            (0, 0.1) = max 10% par actif
            [(0, 0.5), (0, 0.3), ...] = limites par actif
        """
        pass

# Initialisation standard
ef = EfficientFrontier(mu, S)

# Avec ventes √† d√©couvert autoris√©es
ef_short = EfficientFrontier(mu, S, weight_bounds=(-1, 1))

# Avec limite max de 10% par position
ef_constrained = EfficientFrontier(mu, S, weight_bounds=(0, 0.1))
```

## 4.3 Minimiser la Volatilit√©

```python
def min_volatility(self):
    """
    Trouve le portefeuille de variance minimale (MVP).
    
    C'est le point le plus √† gauche sur la fronti√®re efficiente.
    
    Formulation:
        min  w'Œ£w
        s.t. Œ£w = 1
             w ‚â• 0
    
    Returns:
        OrderedDict: Poids optimaux
    """
    pass

# Exemple
ef = EfficientFrontier(mu, S)
weights = ef.min_volatility()
print("Portefeuille de variance minimale:")
for ticker, weight in ef.clean_weights().items():
    if weight > 0.001:
        print(f"  {ticker}: {weight:.2%}")

# Performance
ret, vol, sharpe = ef.portfolio_performance(verbose=True)
"""
Expected annual return: 15.2%
Annual volatility: 12.1%
Sharpe Ratio: 1.01
"""
```

## 4.4 Maximiser le Sharpe Ratio

```python
def max_sharpe(self, risk_free_rate=0.0):
    """
    Trouve le portefeuille qui maximise le Sharpe Ratio.
    
    Aussi appel√© "portefeuille tangent" car il est tangent √† la
    ligne du march√© des capitaux (CML - Capital Market Line).
    
    Sharpe Ratio = (Œº_p - R_f) / œÉ_p
    
    Args:
        risk_free_rate: Taux sans risque (annualis√©, m√™me fr√©quence que mu)
    
    Note: Utilise une transformation convexe pour r√©soudre ce
    probl√®me non-convexe.
    """
    pass

# Exemple
ef = EfficientFrontier(mu, S)
weights = ef.max_sharpe(risk_free_rate=0.02)  # Rf = 2%

print("Portefeuille Max Sharpe:")
cleaned = ef.clean_weights()
for ticker, weight in cleaned.items():
    if weight > 0.001:
        print(f"  {ticker}: {weight:.2%}")

# Performance
ret, vol, sharpe = ef.portfolio_performance(verbose=True, risk_free_rate=0.02)
"""
Expected annual return: 28.5%
Annual volatility: 18.3%
Sharpe Ratio: 1.45
"""
```

## 4.5 Rendement Cible (efficient_return)

```python
def efficient_return(self, target_return, market_neutral=False):
    """
    Portefeuille de Markowitz: Minimise la volatilit√© pour un
    rendement cible.
    
    Formulation:
        min  w'Œ£w
        s.t. w'Œº ‚â• target_return
             Œ£w = 1
    
    Args:
        target_return: Rendement annualis√© cible (ex: 0.15 pour 15%)
        market_neutral: Si True, les poids somment √† 0 (long/short)
    """
    pass

# Exemple: portefeuille visant 20% de rendement
ef = EfficientFrontier(mu, S)
weights = ef.efficient_return(target_return=0.20)
ef.portfolio_performance(verbose=True)

# Portefeuille market-neutral (long/short, poids = 0)
ef_neutral = EfficientFrontier(mu, S, weight_bounds=(-1, 1))
weights_neutral = ef_neutral.efficient_return(
    target_return=0.15, 
    market_neutral=True
)
print(f"Somme des poids: {sum(weights_neutral.values()):.4f}")  # ‚âà 0
```

## 4.6 Risque Cible (efficient_risk)

```python
def efficient_risk(self, target_volatility, market_neutral=False):
    """
    Maximise le rendement pour une volatilit√© cible.
    
    Formulation:
        max  w'Œº
        s.t. w'Œ£w ‚â§ target_volatility¬≤
             Œ£w = 1
    
    Args:
        target_volatility: Volatilit√© annualis√©e cible (ex: 0.15 pour 15%)
    """
    pass

# Exemple: max rendement avec volatilit√© ‚â§ 15%
ef = EfficientFrontier(mu, S)
weights = ef.efficient_risk(target_volatility=0.15)
ret, vol, sharpe = ef.portfolio_performance(verbose=True)
```

## 4.7 Utilit√© Quadratique

```python
def max_quadratic_utility(self, risk_aversion=1, market_neutral=False):
    """
    Maximise l'utilit√© quadratique.
    
    U(w) = w'Œº - (Œ¥/2) * w'Œ£w
    
    Args:
        risk_aversion (Œ¥): Coefficient d'aversion au risque
            - Œ¥ = 0: Maximise uniquement le rendement (tr√®s risqu√©)
            - Œ¥ = 1: √âquilibre rendement/risque standard
            - Œ¥ ‚Üí ‚àû: Minimise uniquement le risque
    """
    pass

# Exemples avec diff√©rentes aversions au risque
for delta in [0.5, 1, 2, 5]:
    ef = EfficientFrontier(mu, S)
    ef.max_quadratic_utility(risk_aversion=delta)
    ret, vol, sharpe = ef.portfolio_performance()
    print(f"Œ¥={delta}: Return={ret:.1%}, Vol={vol:.1%}, Sharpe={sharpe:.2f}")
```

## 4.8 Nettoyage et Sauvegarde des Poids

```python
# Nettoyer les poids (arrondir, supprimer les presque-z√©ros)
cleaned = ef.clean_weights(cutoff=0.001, rounding=4)
# cutoff: Poids < cutoff sont mis √† 0
# rounding: Nombre de d√©cimales

# Sauvegarder les poids
ef.save_weights_to_file("portfolio_weights.csv")  # ou .json, .txt
```

---

# 5. FONCTIONS OBJECTIF (OBJECTIVE FUNCTIONS)

## 5.1 Vue d'ensemble

```python
"""
Module objective_functions
==========================
Fonctions objectif utilis√©es dans l'optimisation.

Peuvent √™tre utilis√©es:
1. En interne par EfficientFrontier
2. Comme objectifs personnalis√©s avec add_objective()
3. Pour calculer des m√©triques sur un portefeuille existant
"""
from pypfopt import objective_functions
```

## 5.2 Fonctions Principales

```python
def portfolio_variance(w, cov_matrix):
    """
    Variance du portefeuille: w'Œ£w
    
    Args:
        w: Poids (np.array ou cp.Variable)
        cov_matrix: Matrice de covariance
    
    Returns:
        Variance (œÉ¬≤), pas volatilit√© (œÉ)
    """
    pass

def portfolio_return(w, expected_returns, negative=True):
    """
    Rendement du portefeuille: w'Œº
    
    Args:
        negative: Si True, retourne -w'Œº (pour minimisation)
    """
    pass

def sharpe_ratio(w, expected_returns, cov_matrix, risk_free_rate=0.0, negative=True):
    """
    Sharpe Ratio: (w'Œº - Rf) / œÉ
    """
    pass

def quadratic_utility(w, expected_returns, cov_matrix, risk_aversion, negative=True):
    """
    Utilit√© quadratique: w'Œº - (Œ¥/2) * w'Œ£w
    """
    pass
```

## 5.3 R√©gularisation L2

```python
def L2_reg(w, gamma=1):
    """
    R√©gularisation L2: Œ≥ * ||w||¬≤
    
    Ajoute une p√©nalit√© sur les poids extr√™mes.
    Encourage des portefeuilles plus diversifi√©s.
    
    Args:
        gamma: Force de la r√©gularisation
            - gamma = 0: Pas de r√©gularisation
            - gamma = 1: R√©gularisation mod√©r√©e
            - gamma ‚Üí ‚àû: Force les poids vers l'√©quipond√©ration
    """
    pass

# Exemple: Max Sharpe avec r√©gularisation L2
ef = EfficientFrontier(mu, S)
ef.add_objective(objective_functions.L2_reg, gamma=0.5)
weights = ef.max_sharpe()

# Comparer avec/sans r√©gularisation
print("Nombre de positions non-nulles:")
print(f"  Sans L2: {sum(1 for w in ef_no_reg.clean_weights().values() if w > 0.01)}")
print(f"  Avec L2: {sum(1 for w in ef.clean_weights().values() if w > 0.01)}")
```

## 5.4 Co√ªts de Transaction

```python
def transaction_cost(w, w_prev, k=0.001):
    """
    Mod√®le simple de co√ªts de transaction.
    
    cost = k * ||w - w_prev||‚ÇÅ
    
    Args:
        w: Nouveaux poids
        w_prev: Anciens poids
        k: Co√ªt par unit√© de poids √©chang√©e (d√©faut: 10 bps)
    """
    pass

# Exemple: Rebalancement avec co√ªts
w_current = np.array([0.25, 0.25, 0.25, 0.25, 0, 0, 0, 0])  # Poids actuels

ef = EfficientFrontier(mu, S)
ef.add_objective(objective_functions.transaction_cost, w_prev=w_current, k=0.001)
weights = ef.max_sharpe()
```

## 5.5 Tracking Error

```python
def ex_ante_tracking_error(w, cov_matrix, benchmark_weights):
    """
    Tracking Error ex-ante (pr√©vu): (w - w_b)'Œ£(w - w_b)
    
    Mesure l'√©cart attendu par rapport √† un benchmark.
    
    Args:
        benchmark_weights: Poids du benchmark (ex: S&P 500)
    """
    pass

def ex_post_tracking_error(w, historic_returns, benchmark_returns):
    """
    Tracking Error ex-post (r√©alis√©): Var(r_p - r_b)
    
    Mesure l'√©cart historique par rapport √† un benchmark.
    """
    pass

# Exemple: Minimiser la volatilit√© tout en restant proche du benchmark
benchmark = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3])  # √âquipond√©r√©

ef = EfficientFrontier(mu, S)
ef.add_objective(
    objective_functions.ex_ante_tracking_error, 
    cov_matrix=S.values, 
    benchmark_weights=benchmark
)
weights = ef.min_volatility()
```

## 5.6 Ajouter des Contraintes et Objectifs Personnalis√©s

```python
# Ajouter une contrainte
ef = EfficientFrontier(mu, S)

# Contrainte: poids de AAPL ‚â• 5%
ef.add_constraint(lambda w: w[0] >= 0.05)

# Contrainte: somme de secteur Tech ‚â§ 40%
tech_indices = [0, 1, 2, 3]  # AAPL, MSFT, GOOGL, AMZN
ef.add_constraint(lambda w: sum(w[i] for i in tech_indices) <= 0.40)

# Ajouter un objectif personnalis√©
def custom_objective(w, extra_param=1):
    return extra_param * cp.norm(w, 1)  # P√©nalit√© L1

ef.add_objective(custom_objective, extra_param=0.1)

# Optimiser
weights = ef.max_sharpe()
```

---

# 6. MOD√àLE BLACK-LITTERMAN

## 6.1 Introduction

```python
"""
Mod√®le Black-Litterman (1992)
=============================
Combine un PRIOR (estimation pr√©alable des rendements) avec les VIEWS
(opinions de l'investisseur) pour obtenir un POSTERIOR (estimation combin√©e).

Avantages:
1. Incorpore les opinions de l'investisseur de fa√ßon rationnelle
2. Produit des portefeuilles plus stables que MVO classique
3. R√©duit les positions extr√™mes

Formule du Posterior:
    E[R] = [(œÑŒ£)‚Åª¬π + P'Œ©‚Åª¬πP]‚Åª¬π √ó [(œÑŒ£)‚Åª¬πœÄ + P'Œ©‚Åª¬πQ]

O√π:
    œÄ = Prior (souvent market-implied returns)
    P = Matrice de picking (quels actifs concern√©s par les views)
    Q = Vecteur des views
    Œ© = Incertitude sur les views
    œÑ = Scalaire (poids du prior vs views, typiquement 0.05)
    Œ£ = Matrice de covariance
"""
from pypfopt import BlackLittermanModel, black_litterman
```

## 6.2 Rendements Implicites du March√©

```python
def market_implied_prior_returns(market_caps, risk_aversion, cov_matrix, risk_free_rate=0.0):
    """
    Calcule les rendements implicites du march√© (prior).
    
    Id√©e: Si le march√© est √† l'√©quilibre, les poids de march√© sont optimaux.
    On peut "reverse-engineer" les rendements esp√©r√©s implicites.
    
    Formule:
        œÄ = Œ¥Œ£w_mkt + Rf
    
    Args:
        market_caps: Capitalisation boursi√®re de chaque actif
        risk_aversion (Œ¥): Aversion au risque du march√©
        cov_matrix: Matrice de covariance
        risk_free_rate: Taux sans risque
    """
    pass

def market_implied_risk_aversion(market_prices, frequency=252, risk_free_rate=0.0):
    """
    Estime l'aversion au risque implicite du march√©.
    
    Œ¥ = (R_m - Rf) / œÉ¬≤_m
    
    Args:
        market_prices: Prix du march√© (ex: SPY, S&P 500)
    """
    pass

# Exemple
import yfinance as yf

# Charger les prix du march√© (S&P 500)
spy = yf.download('SPY', start='2018-01-01')['Adj Close']

# Estimer l'aversion au risque
delta = black_litterman.market_implied_risk_aversion(spy, risk_free_rate=0.02)
print(f"Aversion au risque implicite: {delta:.2f}")

# Capitalisations boursi√®res (en milliards)
mcaps = {
    'AAPL': 2800,
    'MSFT': 2500,
    'GOOGL': 1800,
    'AMZN': 1500,
    'META': 800,
    'JPM': 500,
    'BAC': 300,
    'XOM': 450
}

# Calculer le prior
prior = black_litterman.market_implied_prior_returns(
    mcaps, 
    delta, 
    S,
    risk_free_rate=0.02
)
print("\nRendements implicites du march√©:")
print(prior.sort_values(ascending=False))
```

## 6.3 D√©finir les Views

```python
"""
Types de Views
==============
1. Absolute Views: "AAPL va retourner 25%"
2. Relative Views: "GOOGL va surperformer META de 5%"

Format pour absolute_views: {ticker: expected_return}
Format pour views d√©taill√©es: P (picking matrix) et Q (vector)
"""

# M√©thode 1: Views Absolues (simple)
views = {
    'AAPL': 0.25,   # AAPL va faire 25%
    'META': -0.10,  # META va faire -10%
    'JPM': 0.15     # JPM va faire 15%
}

bl = BlackLittermanModel(
    S,
    pi=prior,           # ou "market", "equal"
    absolute_views=views
)

# M√©thode 2: Views avec P et Q (pour views relatives)
# View 1: AAPL va faire 25%
# View 2: GOOGL va surperformer META de 5%
# View 3: JPM + BAC vont surperformer XOM de 10%

Q = np.array([0.25, 0.05, 0.10]).reshape(-1, 1)

# P: Matrice de picking (lignes = views, colonnes = actifs)
# Ordre des actifs: AAPL, MSFT, GOOGL, AMZN, META, JPM, BAC, XOM
P = np.array([
    [1, 0, 0, 0, 0, 0, 0, 0],       # AAPL
    [0, 0, 1, 0, -1, 0, 0, 0],      # GOOGL - META
    [0, 0, 0, 0, 0, 0.5, 0.5, -1],  # 0.5*JPM + 0.5*BAC - XOM
])

bl = BlackLittermanModel(
    S,
    pi=prior,
    Q=Q,
    P=P
)
```

## 6.4 Classe BlackLittermanModel

```python
class BlackLittermanModel:
    def __init__(
        self,
        cov_matrix,
        pi=None,                    # Prior: array, "market", ou "equal"
        absolute_views=None,        # Views absolues (dict)
        Q=None,                     # Vecteur des views
        P=None,                     # Matrice de picking
        omega=None,                 # Incertitude des views: array, "default", "idzorek"
        view_confidences=None,      # Confiances pour m√©thode Idzorek
        tau=0.05,                   # Poids prior vs views
        risk_aversion=1,            # Aversion au risque
        market_caps=None,           # Pour pi="market"
        risk_free_rate=0.0
    ):
        """
        Initialise le mod√®le Black-Litterman.
        
        omega (incertitude des views):
        - "default": Proportionnel √† la variance des assets dans la view
        - "idzorek": Utilise view_confidences (0 √† 1) pour chaque view
        - array: Matrice diagonale personnalis√©e
        """
        pass
    
    def bl_returns(self):
        """Calcule les rendements post√©rieurs."""
        pass
    
    def bl_cov(self):
        """Calcule la covariance post√©rieure."""
        pass
    
    def bl_weights(self, risk_aversion=None):
        """Calcule les poids implicites (sans optimisation)."""
        pass

# Exemple complet
bl = BlackLittermanModel(
    S,
    pi="market",
    market_caps=mcaps,
    absolute_views={'AAPL': 0.25, 'META': -0.05},
    omega="default",
    tau=0.05
)

# Obtenir les rendements post√©rieurs
posterior_returns = bl.bl_returns()
print("\nRendements post√©rieurs Black-Litterman:")
print(posterior_returns.sort_values(ascending=False))

# Utiliser avec EfficientFrontier
ef = EfficientFrontier(posterior_returns, S)
weights = ef.max_sharpe()
ef.portfolio_performance(verbose=True)
```

## 6.5 M√©thode Idzorek

```python
"""
M√©thode Idzorek (2005)
======================
Permet de sp√©cifier l'incertitude des views en pourcentage de confiance.

Confiance 0% = On ignore compl√®tement la view
Confiance 100% = La view est certaine
"""

# Views avec niveaux de confiance
views = {
    'AAPL': 0.20,   # AAPL +20%
    'GOOGL': 0.15,  # GOOGL +15%  
    'META': -0.10   # META -10%
}

# Confiances (entre 0 et 1)
confidences = [0.8, 0.6, 0.5]  # 80%, 60%, 50%

bl = BlackLittermanModel(
    S,
    pi="market",
    market_caps=mcaps,
    absolute_views=views,
    omega="idzorek",
    view_confidences=confidences,
    tau=0.05
)

posterior = bl.bl_returns()
```

---

# 7. HRP - HIERARCHICAL RISK PARITY

## 7.1 Introduction

```python
"""
Hierarchical Risk Parity (HRP)
==============================
D√©velopp√© par Marcos L√≥pez de Prado (2016).

Alternative √† MVO qui:
1. N'utilise PAS de matrice inverse (plus stable)
2. N'a PAS besoin des rendements esp√©r√©s
3. Utilise le clustering hi√©rarchique pour diversifier

Algorithme en 3 √©tapes:
1. Tree Clustering: Grouper les actifs par corr√©lation
2. Quasi-Diagonalization: R√©organiser la matrice de covariance
3. Recursive Bisection: Allouer le capital r√©cursivement

Avantages:
- Plus robuste hors-√©chantillon que MVO
- Pas besoin d'estimer les rendements esp√©r√©s
- Produit des portefeuilles naturellement diversifi√©s
"""
from pypfopt import HRPOpt
```

## 7.2 Classe HRPOpt

```python
class HRPOpt:
    """
    Optimisation par Hierarchical Risk Parity.
    """
    
    def __init__(self, returns=None, cov_matrix=None):
        """
        Initialise HRP.
        
        Args:
            returns: DataFrame de rendements historiques
            cov_matrix: Matrice de covariance (alternative aux returns)
        
        Note: Fournir returns OU cov_matrix (pas les deux obligatoirement).
        """
        pass
    
    def optimize(self, linkage_method="single"):
        """
        Calcule les poids HRP.
        
        Args:
            linkage_method: M√©thode de clustering scipy
                - "single": Plus proches voisins
                - "complete": Plus lointains voisins
                - "average": Moyenne des distances
                - "ward": Minimise la variance intra-cluster
        
        Returns:
            OrderedDict: Poids optimaux
        """
        pass

# Exemple
# Calculer les rendements
returns = df.pct_change().dropna()

# HRP
hrp = HRPOpt(returns)
weights = hrp.optimize(linkage_method="single")

print("Poids HRP:")
for ticker, weight in sorted(weights.items(), key=lambda x: -x[1]):
    print(f"  {ticker}: {weight:.2%}")

# Performance
ret, vol, sharpe = hrp.portfolio_performance(verbose=True, frequency=252)
```

## 7.3 Visualisation du Dendrogramme

```python
from pypfopt import plotting
import matplotlib.pyplot as plt

# Cr√©er le portefeuille HRP
hrp = HRPOpt(returns)
weights = hrp.optimize()

# Afficher le dendrogramme
fig, ax = plt.subplots(figsize=(12, 6))
plotting.plot_dendrogram(hrp, ax=ax, show_tickers=True)
plt.title("Clustering Hi√©rarchique des Actifs")
plt.tight_layout()
plt.show()
```

## 7.4 HRP vs MVO - Comparaison

```python
"""
Comparaison HRP vs MVO
======================
"""
# MVO
mu = expected_returns.mean_historical_return(df)
S = risk_models.sample_cov(df)

ef = EfficientFrontier(mu, S)
mvo_weights = ef.max_sharpe()
mvo_ret, mvo_vol, mvo_sharpe = ef.portfolio_performance()

# HRP
hrp = HRPOpt(returns)
hrp_weights = hrp.optimize()
hrp_ret, hrp_vol, hrp_sharpe = hrp.portfolio_performance()

print("Comparaison MVO vs HRP:")
print(f"{'M√©trique':<20} {'MVO':>10} {'HRP':>10}")
print("-" * 40)
print(f"{'Rendement'::<20} {mvo_ret:>10.1%} {hrp_ret:>10.1%}")
print(f"{'Volatilit√©':<20} {mvo_vol:>10.1%} {hrp_vol:>10.1%}")
print(f"{'Sharpe Ratio':<20} {mvo_sharpe:>10.2f} {hrp_sharpe:>10.2f}")
print(f"{'Nb positions':<20} {sum(1 for w in mvo_weights.values() if w>0.01):>10} {sum(1 for w in hrp_weights.values() if w>0.01):>10}")
```

---

# 8. CVaR ET SEMIVARIANCE

## 8.1 CVaR (Conditional Value at Risk)

```python
"""
CVaR (Conditional Value at Risk)
================================
Aussi appel√© Expected Shortfall (ES).

VaR (Value at Risk): "La perte maximale avec probabilit√© (1-Œ≤)"
CVaR: "La perte moyenne dans les (1-Œ≤)% pires cas"

Exemple (Œ≤=95%):
- VaR 95%: "On ne perd pas plus de X dans 95% des cas"
- CVaR 95%: "Dans les 5% pires cas, on perd en moyenne Y"

Avantages du CVaR:
- Coh√©rent (satisfait les axiomes des mesures de risque)
- Capture le risque de queue (tail risk)
- Convexe (facile √† optimiser)
"""
from pypfopt.efficient_frontier import EfficientCVaR

class EfficientCVaR(EfficientFrontier):
    """
    Optimisation sur la fronti√®re moyenne-CVaR.
    """
    
    def __init__(
        self,
        expected_returns,
        returns,              # Rendements historiques (pas juste covariance!)
        beta=0.95,           # Niveau de confiance
        weight_bounds=(0, 1),
        solver=None,
        verbose=False,
        solver_options=None
    ):
        """
        Args:
            returns: DataFrame de rendements historiques (REQUIS)
            beta: Niveau de confiance (0.95 = CVaR sur les 5% pires cas)
        """
        pass
    
    def min_cvar(self, market_neutral=False):
        """Minimise le CVaR."""
        pass
    
    def efficient_return(self, target_return, market_neutral=False):
        """Minimise le CVaR pour un rendement cible."""
        pass
    
    def efficient_risk(self, target_cvar, market_neutral=False):
        """Maximise le rendement pour un CVaR cible."""
        pass

# Exemple
returns = df.pct_change().dropna()
mu = expected_returns.mean_historical_return(df)

# CVaR au niveau 95%
ef_cvar = EfficientCVaR(mu, returns, beta=0.95)
weights = ef_cvar.min_cvar()

print("Portefeuille Min-CVaR:")
for ticker, weight in ef_cvar.clean_weights().items():
    if weight > 0.01:
        print(f"  {ticker}: {weight:.2%}")

# Performance
ret, cvar = ef_cvar.portfolio_performance(verbose=True)
print(f"\nExpected Return: {ret:.1%}")
print(f"CVaR (95%): {cvar:.2%}")
```

## 8.2 Semivariance

```python
"""
Semivariance / Semid√©viation
============================
Mesure de risque qui ne consid√®re que les rendements N√âGATIFS.

Id√©e: Les investisseurs ne se soucient pas de la "volatilit√© positive".

Semivariance = E[min(r - B, 0)¬≤]
O√π B = benchmark (souvent 0 ou le taux sans risque)
"""
from pypfopt.efficient_frontier import EfficientSemivariance

class EfficientSemivariance(EfficientFrontier):
    """
    Optimisation sur la fronti√®re moyenne-semivariance.
    """
    
    def __init__(
        self,
        expected_returns,
        returns,
        benchmark=0,           # Benchmark pour le downside
        frequency=252,
        weight_bounds=(0, 1),
        solver=None,
        verbose=False,
        solver_options=None
    ):
        pass
    
    def min_semivariance(self, market_neutral=False):
        """Minimise la semivariance."""
        pass
    
    def efficient_return(self, target_return, market_neutral=False):
        """Minimise la semivariance pour un rendement cible."""
        pass
    
    def efficient_risk(self, target_semideviation, market_neutral=False):
        """Maximise le rendement pour une semid√©viation cible."""
        pass

# Exemple
ef_semi = EfficientSemivariance(mu, returns, benchmark=0)
weights = ef_semi.min_semivariance()

print("Portefeuille Min-Semivariance:")
for ticker, weight in ef_semi.clean_weights().items():
    if weight > 0.01:
        print(f"  {ticker}: {weight:.2%}")

# Performance
ret, semi = ef_semi.portfolio_performance(verbose=True)
```

---

# 9. ALLOCATION DISCR√àTE

## 9.1 Du Poids Continu aux Actions

```python
"""
Allocation Discr√®te
===================
Les poids optimaux sont CONTINUS (ex: 15.37%).
En pratique, on doit acheter un NOMBRE ENTIER d'actions.

Probl√®me:
- Portefeuille de $10,000
- AAPL poids optimal = 15.37% = $1,537
- Prix AAPL = $175
- Actions th√©oriques = $1,537 / $175 = 8.78

On ne peut pas acheter 8.78 actions!

Solution: Algorithmes d'allocation discr√®te.
"""
from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices
```

## 9.2 Classe DiscreteAllocation

```python
class DiscreteAllocation:
    """
    Convertit les poids continus en allocation discr√®te.
    """
    
    def __init__(
        self,
        weights,                    # Dict {ticker: weight}
        latest_prices,              # pd.Series des prix actuels
        total_portfolio_value=10000,
        short_ratio=None            # Pour portefeuilles long/short
    ):
        pass
    
    def greedy_portfolio(self, reinvest=False, verbose=False):
        """
        Allocation gloutonne (greedy).
        
        Algorithme:
        1. Pour chaque actif, acheter floor(weight * value / price) actions
        2. Avec le cash restant, acheter l'actif le plus sous-pond√©r√©
        3. R√©p√©ter jusqu'√† √©puisement du cash
        
        Args:
            reinvest: R√©investir le cash des ventes √† d√©couvert?
            verbose: Afficher les d√©tails
        
        Returns:
            (allocation, leftover): (dict d'actions, cash restant)
        """
        pass
    
    def lp_portfolio(self, reinvest=False, verbose=False, solver=None):
        """
        Allocation par programmation lin√©aire.
        
        R√©sout un probl√®me d'optimisation enti√®re pour minimiser
        l'√©cart par rapport aux poids cibles.
        
        Plus pr√©cis mais plus lent que greedy.
        """
        pass

# Exemple complet
# 1. Optimiser
ef = EfficientFrontier(mu, S)
weights = ef.max_sharpe()
cleaned_weights = ef.clean_weights()

# 2. Obtenir les prix actuels
latest_prices = get_latest_prices(df)
# Ou manuellement:
# latest_prices = df.iloc[-1]

# 3. Allocation discr√®te
da = DiscreteAllocation(
    cleaned_weights,
    latest_prices,
    total_portfolio_value=50000  # $50,000 √† investir
)

# M√©thode Greedy
allocation, leftover = da.greedy_portfolio(verbose=True)

print("\nAllocation (Greedy):")
print("-" * 40)
for ticker, shares in allocation.items():
    price = latest_prices[ticker]
    value = shares * price
    print(f"  {ticker}: {shares} actions (${value:,.2f})")
print(f"\nCash restant: ${leftover:,.2f}")

# M√©thode LP (plus pr√©cise)
da2 = DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=50000)
allocation_lp, leftover_lp = da2.lp_portfolio(verbose=True)
print(f"\nCash restant (LP): ${leftover_lp:,.2f}")
```

## 9.3 Portefeuille Long/Short

```python
# Pour les portefeuilles avec ventes √† d√©couvert
ef = EfficientFrontier(mu, S, weight_bounds=(-1, 1))
weights = ef.efficient_return(target_return=0.15, market_neutral=True)

da = DiscreteAllocation(
    weights,
    latest_prices,
    total_portfolio_value=100000,
    short_ratio=0.3  # 130/30 portfolio
)

allocation, leftover = da.greedy_portfolio(reinvest=True)

print("Allocation Long/Short:")
longs = {k: v for k, v in allocation.items() if v > 0}
shorts = {k: v for k, v in allocation.items() if v < 0}

print("\nPositions LONG:")
for ticker, shares in longs.items():
    print(f"  {ticker}: +{shares} actions")

print("\nPositions SHORT:")
for ticker, shares in shorts.items():
    print(f"  {ticker}: {shares} actions")
```

---

# 10. EXEMPLES COMPLETS

## 10.1 Workflow Standard

```python
"""
Workflow Complet PyPortfolioOpt
===============================
De A √† Z: donn√©es brutes ‚Üí ordres d'achat
"""
import pandas as pd
import numpy as np
import yfinance as yf
from pypfopt import EfficientFrontier, expected_returns, risk_models
from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices

# ============================================
# 1. CHARGER LES DONN√âES
# ============================================
tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 
           'JPM', 'BAC', 'XOM', 'JNJ', 'PG']

df = yf.download(tickers, start='2019-01-01', end='2024-01-01')['Adj Close']
print(f"Donn√©es: {df.shape[0]} jours, {df.shape[1]} actifs")

# ============================================
# 2. CALCULER LES ESTIMATIONS
# ============================================
# Rendements esp√©r√©s (EMA pour plus de r√©activit√©)
mu = expected_returns.ema_historical_return(df, span=252)

# Matrice de covariance (Ledoit-Wolf shrinkage pour stabilit√©)
S = risk_models.CovarianceShrinkage(df).ledoit_wolf()

print("\nRendements esp√©r√©s:")
print(mu.sort_values(ascending=False).round(3))

# ============================================
# 3. OPTIMISER LE PORTEFEUILLE
# ============================================
# Max Sharpe avec contraintes
ef = EfficientFrontier(mu, S)

# Contrainte: max 20% par position
ef = EfficientFrontier(mu, S, weight_bounds=(0, 0.20))

# Ajouter r√©gularisation L2 pour diversifier
from pypfopt import objective_functions
ef.add_objective(objective_functions.L2_reg, gamma=0.1)

# Optimiser
weights = ef.max_sharpe(risk_free_rate=0.04)  # Rf = 4%
cleaned_weights = ef.clean_weights()

print("\nPoids optimaux:")
for ticker, weight in sorted(cleaned_weights.items(), key=lambda x: -x[1]):
    if weight > 0.01:
        print(f"  {ticker}: {weight:.1%}")

# Performance attendue
ret, vol, sharpe = ef.portfolio_performance(verbose=True, risk_free_rate=0.04)

# ============================================
# 4. ALLOCATION DISCR√àTE
# ============================================
portfolio_value = 100000  # $100,000

latest_prices = get_latest_prices(df)
da = DiscreteAllocation(cleaned_weights, latest_prices, 
                        total_portfolio_value=portfolio_value)

allocation, leftover = da.greedy_portfolio()

print(f"\n{'='*50}")
print(f"ORDRES D'ACHAT (Budget: ${portfolio_value:,})")
print(f"{'='*50}")
print(f"{'Ticker':<8} {'Actions':>8} {'Prix':>10} {'Valeur':>12}")
print("-" * 50)

total_invested = 0
for ticker, shares in allocation.items():
    price = latest_prices[ticker]
    value = shares * price
    total_invested += value
    print(f"{ticker:<8} {shares:>8} ${price:>9.2f} ${value:>11,.2f}")

print("-" * 50)
print(f"{'Total investi':<28} ${total_invested:>11,.2f}")
print(f"{'Cash restant':<28} ${leftover:>11,.2f}")
```

## 10.2 Comparaison de Strat√©gies

```python
"""
Comparer diff√©rentes strat√©gies d'optimisation
"""
import pandas as pd
import numpy as np
from pypfopt import (
    EfficientFrontier, HRPOpt, BlackLittermanModel,
    expected_returns, risk_models, black_litterman
)

# Donn√©es
returns = df.pct_change().dropna()
mu = expected_returns.mean_historical_return(df)
S = risk_models.sample_cov(df)

results = {}

# ============================================
# 1. MVO - Max Sharpe
# ============================================
ef = EfficientFrontier(mu, S)
ef.max_sharpe()
ret, vol, sharpe = ef.portfolio_performance()
results['MVO Max Sharpe'] = {'return': ret, 'volatility': vol, 'sharpe': sharpe}

# ============================================
# 2. MVO - Min Volatility
# ============================================
ef = EfficientFrontier(mu, S)
ef.min_volatility()
ret, vol, sharpe = ef.portfolio_performance()
results['MVO Min Vol'] = {'return': ret, 'volatility': vol, 'sharpe': sharpe}

# ============================================
# 3. HRP
# ============================================
hrp = HRPOpt(returns)
hrp.optimize()
ret, vol, sharpe = hrp.portfolio_performance()
results['HRP'] = {'return': ret, 'volatility': vol, 'sharpe': sharpe}

# ============================================
# 4. Equal Weight
# ============================================
n = len(df.columns)
ew_ret = (returns.mean() * 252).mean()
ew_vol = np.sqrt(np.dot(np.ones(n)/n, np.dot(S, np.ones(n)/n)))
ew_sharpe = ew_ret / ew_vol
results['Equal Weight'] = {'return': ew_ret, 'volatility': ew_vol, 'sharpe': ew_sharpe}

# ============================================
# Afficher les r√©sultats
# ============================================
print("\nCOMPARAISON DES STRAT√âGIES")
print("=" * 60)
print(f"{'Strat√©gie':<20} {'Return':>12} {'Volatility':>12} {'Sharpe':>10}")
print("-" * 60)

for name, metrics in results.items():
    print(f"{name:<20} {metrics['return']:>11.1%} {metrics['volatility']:>11.1%} {metrics['sharpe']:>10.2f}")
```

## 10.3 Black-Litterman avec Views

```python
"""
Exemple Black-Litterman Complet
"""
import yfinance as yf
from pypfopt import (
    EfficientFrontier, BlackLittermanModel,
    expected_returns, risk_models, black_litterman
)

# Charger les donn√©es
tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'JPM']
df = yf.download(tickers, start='2020-01-01')['Adj Close']
spy = yf.download('SPY', start='2020-01-01')['Adj Close']

# Covariance
S = risk_models.CovarianceShrinkage(df).ledoit_wolf()

# Capitalisation boursi√®re (milliards)
mcaps = {
    'AAPL': 2900, 'MSFT': 2800, 'GOOGL': 1900, 'AMZN': 1600,
    'META': 1200, 'NVDA': 1100, 'TSLA': 800, 'JPM': 500
}

# Aversion au risque implicite
delta = black_litterman.market_implied_risk_aversion(spy)
print(f"Aversion au risque implicite: {delta:.2f}")

# Prior (rendements implicites du march√©)
prior = black_litterman.market_implied_prior_returns(mcaps, delta, S)
print("\nRendements implicites (prior):")
print(prior.round(3))

# ============================================
# D√âFINIR LES VIEWS
# ============================================
"""
Nos views:
1. NVDA va surperformer le march√© de 15% (IA boom)
2. TSLA va sous-performer de 10%
3. AAPL vs MSFT: AAPL surperforme de 3%
"""

views = {
    'NVDA': prior['NVDA'] + 0.15,  # +15% vs prior
    'TSLA': prior['TSLA'] - 0.10,  # -10% vs prior
    'AAPL': prior['AAPL'] + 0.03,  # +3% vs MSFT (simplifi√©)
}

confidences = [0.75, 0.60, 0.50]  # Niveaux de confiance

# ============================================
# BLACK-LITTERMAN
# ============================================
bl = BlackLittermanModel(
    S,
    pi=prior,
    absolute_views=views,
    omega="idzorek",
    view_confidences=confidences,
    tau=0.05
)

# Rendements post√©rieurs
posterior = bl.bl_returns()
print("\nRendements post√©rieurs (Black-Litterman):")
print(posterior.round(3))

# Comparer prior vs posterior
comparison = pd.DataFrame({
    'Prior': prior,
    'Posterior': posterior,
    'Diff√©rence': posterior - prior
})
print("\nComparaison Prior vs Posterior:")
print(comparison.round(3))

# ============================================
# OPTIMISER AVEC LE POSTERIOR
# ============================================
ef_bl = EfficientFrontier(posterior, S)
ef_bl.max_sharpe()

print("\nPortefeuille Black-Litterman optimis√©:")
for ticker, weight in ef_bl.clean_weights().items():
    if weight > 0.01:
        print(f"  {ticker}: {weight:.1%}")

ef_bl.portfolio_performance(verbose=True)
```

## 10.4 Visualisation

```python
"""
Visualisations avec PyPortfolioOpt
"""
import matplotlib.pyplot as plt
from pypfopt import plotting

# ============================================
# 1. Fronti√®re Efficiente
# ============================================
from pypfopt import CLA

mu = expected_returns.mean_historical_return(df)
S = risk_models.sample_cov(df)

# CLA permet de tracer la fronti√®re compl√®te
cla = CLA(mu, S)
cla.max_sharpe()

fig, ax = plt.subplots(figsize=(10, 6))
plotting.plot_efficient_frontier(cla, ax=ax, show_assets=True)
plt.title("Fronti√®re Efficiente")
plt.tight_layout()
plt.savefig("efficient_frontier.png", dpi=150)
plt.show()

# ============================================
# 2. Matrice de Corr√©lation
# ============================================
fig, ax = plt.subplots(figsize=(10, 8))
plotting.plot_covariance(S, ax=ax, show_tickers=True)
plt.title("Matrice de Covariance")
plt.tight_layout()
plt.savefig("covariance_matrix.png", dpi=150)
plt.show()

# ============================================
# 3. Poids du Portefeuille
# ============================================
ef = EfficientFrontier(mu, S)
weights = ef.max_sharpe()
cleaned = ef.clean_weights()

fig, ax = plt.subplots(figsize=(10, 6))
plotting.plot_weights(cleaned, ax=ax)
plt.title("Poids du Portefeuille Max Sharpe")
plt.tight_layout()
plt.savefig("portfolio_weights.png", dpi=150)
plt.show()

# ============================================
# 4. Dendrogramme HRP
# ============================================
returns = df.pct_change().dropna()
hrp = HRPOpt(returns)
hrp.optimize()

fig, ax = plt.subplots(figsize=(12, 6))
plotting.plot_dendrogram(hrp, ax=ax, show_tickers=True)
plt.title("Dendrogramme HRP")
plt.tight_layout()
plt.savefig("hrp_dendrogram.png", dpi=150)
plt.show()
```

---

# ANNEXE: GLOSSAIRE

| Terme | Anglais | D√©finition |
|-------|---------|------------|
| **MVO** | Mean-Variance Optimization | Optimisation Moyenne-Variance de Markowitz |
| **EF** | Efficient Frontier | Fronti√®re Efficiente - ensemble des portefeuilles optimaux |
| **MVP** | Minimum Variance Portfolio | Portefeuille de variance minimale |
| **Sharpe Ratio** | Sharpe Ratio | Rendement exc√©dentaire par unit√© de risque |
| **CAPM** | Capital Asset Pricing Model | Mod√®le d'√©valuation des actifs financiers |
| **HRP** | Hierarchical Risk Parity | Parit√© de risque hi√©rarchique |
| **CVaR** | Conditional Value at Risk | Valeur √† risque conditionnelle (Expected Shortfall) |
| **VaR** | Value at Risk | Valeur √† risque |
| **CLA** | Critical Line Algorithm | Algorithme de la ligne critique |
| **B-L** | Black-Litterman | Mod√®le Black-Litterman |
| **OAS** | Oracle Approximating Shrinkage | Shrinkage approximant l'oracle |
| **L-W** | Ledoit-Wolf | M√©thode de shrinkage Ledoit-Wolf |
| **EMA** | Exponential Moving Average | Moyenne mobile exponentielle |

---

# FIN DU GUIDE

Ce guide couvre l'ensemble des fonctionnalit√©s de PyPortfolioOpt.
Pour plus d'informations, consultez la documentation officielle:
https://pyportfolioopt.readthedocs.io/
